{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d04617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67084ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /Users/shaistasyeda/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378e52b-5771-4b51-80f9-29ba0187237d",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc8c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc162c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1800_1849_tokenized.txt\n",
      "Processed 455320 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1800_1849_tokenized.txt\n",
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1850_1920_tokenized.txt\n",
      "Processed 942551 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1850_1920_tokenized.txt\n",
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1921_1970_tokenized.txt\n",
      "Processed 1339764 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1921_1970_tokenized.txt\n",
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1971_1990_tokenized.txt\n",
      "Processed 1025994 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1971_1990_tokenized.txt\n",
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1991_2006_tokenized.txt\n",
      "Processed 597305 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1991_2006_tokenized.txt\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "# the directory path of tokenized files\n",
    "data_directory = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates'\n",
    "\n",
    "# Initialize an empty list to store sentences\n",
    "sentences = []\n",
    "print(\"here\")\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        # Read the tokenized data from the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_sentences = [line.split() for line in file]\n",
    "\n",
    "        # Add the sentences from this file to the overall list\n",
    "        sentences.extend(file_sentences)\n",
    "        \n",
    "        print(f\"Processed {len(file_sentences)} sentences from {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8027b128-133b-4723-a88f-83e1224ffb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec Model\n",
      "Word2Vec Model training completed\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "print(\"Training Word2Vec Model\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de00433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the saved Word2Vec model\n",
    "model = Word2Vec.load('word2vec_model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82c3ab5-740f-4399-970a-97e74961c9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'woman': [('men', 0.6022253632545471), ('female', 0.5765068531036377), ('sex', 0.5569344162940979), ('unmarried', 0.5505144596099854), ('wife', 0.5437403321266174)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=5)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2089b056-c227-4dcb-9221-d745c73c9355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'women' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find words similar to the word women\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m similar_words \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwomen\u001b[39m\u001b[38;5;124m'\u001b[39m, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilar words to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwomen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilar_words\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'women' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# Find words similar to the word women\n",
    "similar_words = model.wv.most_similar('women', topn=5)\n",
    "print(f\"Similar words to 'women': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dac2610-0743-466b-9d5c-7dcddf8d7c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'woman': [('men', 0.6022253632545471), ('female', 0.5765068531036377), ('sex', 0.5569344162940979), ('unmarried', 0.5505144596099854), ('wife', 0.5437403321266174), ('girl', 0.5319264531135559), ('inspectorinspectorsergeantconstabletotal', 0.4870729446411133), ('bisexual', 0.4854346513748169), ('childbirth', 0.4817197620868683), ('menopause', 0.4792359173297882), ('mother', 0.4747985005378723), ('adult', 0.46753647923469543), ('ranksavon', 0.459628701210022), ('married', 0.45891711115837097), ('widower', 0.45504724979400635)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=15)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5931ff-45ab-4bbb-9bf2-84e90d14b37d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'man': [('men', 0.6573125720024109), ('someone', 0.6129646897315979), ('wife', 0.5151177644729614), ('father', 0.5068652629852295), ('husband', 0.5031120181083679)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c1abfd-9996-4712-bd27-0dd271c4c080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'man': [('men', 0.6573125720024109), ('someone', 0.6129646897315979), ('wife', 0.5151177644729614), ('father', 0.5068652629852295), ('husband', 0.5031120181083679), ('person', 0.5005711913108826), ('lad', 0.49994152784347534), ('somebody', 0.48950695991516113), ('people', 0.4825318157672882), ('loses', 0.4725981056690216), ('forehead', 0.46716415882110596), ('son', 0.4664529860019684), ('chap', 0.46079021692276), ('policeman', 0.45232799649238586), ('fellow', 0.44959431886672974)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=15)\n",
    "print(f\"Similar words to 'man': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b2cf27-0c44-4582-8267-5b131e55d4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'suffrage': [('franchise', 0.6967247128486633), ('elective', 0.44971323013305664), ('enfranchisement', 0.4441656172275543), ('disfranchisement', 0.3948650360107422), ('voter', 0.38702261447906494), ('enfranchising', 0.3859948217868805), ('plebiscito', 0.3855326175689697), ('ballot', 0.3840750753879547), ('democracy', 0.37846261262893677), ('enfranchised', 0.37578168511390686), ('unenfranchised', 0.3753224313259125), ('elector', 0.36752188205718994), ('electorate', 0.36141765117645264), ('voting', 0.3577018678188324), ('electoral', 0.35663434863090515)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word suffrage\n",
    "similar_words = model.wv.most_similar('suffrage', topn=15)\n",
    "print(f\"Similar words to 'suffrage': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc8934a-71e5-4b46-aebc-a860991e7116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'equality': [('equal', 0.7007212042808533), ('discrimination', 0.5479030609130859), ('gender', 0.4699892997741699), ('racial', 0.46831169724464417), ('sex', 0.4617367386817932), ('equalityasked', 0.4479593336582184), ('parity', 0.4447823464870453), ('footing', 0.43004098534584045), ('inequality', 0.42711105942726135), ('counciltechnician', 0.41014912724494934), ('toleration', 0.3866822123527527), ('differentiation', 0.3797881007194519), ('discriminated', 0.37864622473716736), ('ethnicity', 0.37448111176490784), ('discriminationasked', 0.3744088411331177)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar('equality', topn=15)\n",
    "print(f\"Similar words to 'equality': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daafde53-27f7-4fde-9425-c9e208c91fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of 'woman': [ 1.2596273  -0.37490997  0.35141307  1.6662583   1.8601185   1.2944701\n",
      "  1.8451197  -2.613087   -1.0320278  -2.7902799   5.3885818  -2.8061728\n",
      " -4.163704    6.209544   -2.6131723  -0.6906628  -0.09385203 -0.22449662\n",
      "  1.555293    3.4583585  -0.38106006  0.01359362 -2.5155559   0.41958383\n",
      "  0.6414971   0.9862824   5.1001277   2.2969584   2.9962327  -1.571529\n",
      "  1.1931751  -4.8946195  -4.4460225  -0.71358675 -2.5959702  -3.646962\n",
      " -0.7700778   2.4266865  -0.21357638 -5.107355    0.20069548  1.7830408\n",
      " -1.1266327   0.9309858   0.4769537   2.1963851  -3.4812715   2.010043\n",
      " -1.1985118   3.368584   -2.7620614  -0.36982888 -2.9934907  -1.6390448\n",
      "  4.094822    0.68415284  5.205577   -1.0029396  -0.12486371 -0.64282227\n",
      "  1.0746623  -1.7533293  -0.48268116  1.8293387   1.1097598  -1.8652557\n",
      "  4.912996    2.001658    1.3285235   1.673661    0.1836471   5.748503\n",
      "  1.8428426   2.290265   -0.6366504  -2.4045913  -2.7446518  -3.1501203\n",
      " -0.8905128  -2.7381275  -2.1109564   6.778751   -0.81184715 -0.69553465\n",
      " -1.1506182   1.012639    1.6262419  -0.914673   -3.3012912   2.6794071\n",
      " -2.1488993   2.025315   -2.0748749  -0.9490024   0.17871995 -1.4890809\n",
      "  1.6846343   1.0395035  -1.0509653  -1.8686639   5.705066   -3.9907687\n",
      "  1.4411197   1.4247656  -2.005247    0.9311141  -2.7131476   4.9271064\n",
      " -1.9025472  -0.08470346  4.503738   -0.17507505  2.751417    1.5277313\n",
      "  0.631588   -3.1091244   0.29995883  1.920659    2.9440422  -1.393453\n",
      " -1.790168   -1.9734774  -2.072189   -2.8633533  -0.9986128   1.3692895\n",
      "  2.94953     2.1024487   6.7187448   2.6724308  -0.19448553  0.86315775\n",
      "  1.5420799  -0.6329701  -0.31521645  2.2450533   1.5467603  -2.9887965\n",
      " -2.0020769  -1.0335519   2.2571259   1.9424933  -0.63516843 -2.2894225\n",
      "  0.37858075 -1.8008075  -2.3120587   0.92929727  3.5419526  -1.8236154\n",
      "  0.9852579  -3.1469188  -1.5992197   2.1199474   1.2170494   5.1176915\n",
      " -2.3107495   2.0994654  -2.5989587   4.6855145  -1.9081713   2.828311\n",
      "  2.065701   -3.282219    1.6801502   0.90546316 -2.1722102   1.737517\n",
      " -5.5791473   1.2879179  -4.560986    2.3686068  -3.0630856   5.276049\n",
      " -3.5350733  -2.9707985   1.7846304   0.13132064  0.78917503  1.632815\n",
      " -0.11540231 -0.3833839   0.66744643 -2.5368757   0.10168696 -0.91712856\n",
      "  0.76822734 -3.480256   -0.6639378   2.6286767  -1.3377764   1.4703147\n",
      "  1.9825362   4.4232464  -2.308037    1.7602419   3.0446968   0.67290735\n",
      "  1.0286341  -0.6110797  -0.56797504 -3.6062386   0.50156695 -0.861255\n",
      " -0.20858024 -1.6534603  -1.6805516   0.7128805  -1.6051956  -3.1198223\n",
      " -2.4995406   4.1863933  -4.893872   -0.08593574  1.6313444  -1.3259041\n",
      "  1.0050205   3.1181474   2.4972372   1.4290506   1.557976    3.4120834\n",
      " -1.0148941  -1.7089027   2.0419276   2.4478574   0.12362155  1.4401227\n",
      " -0.9496325  -3.0590506   0.5112166   0.10740049  1.7705637   1.8085673\n",
      " -6.745929   -3.654486    0.21944028 -0.75686127 -0.00880294 -0.16345872\n",
      " -0.70916     0.63896096 -3.1139193   1.0837889   0.02455519 -3.4534912\n",
      " -2.5694122   3.0866935   0.6457279   2.2631025   3.0217285  -0.7889637\n",
      "  1.8456708  -3.9690564  -1.9946717   1.459799   -1.5928501  -0.34272653\n",
      "  0.04095579  0.7483787   0.89284277  1.5672256  -0.24657261  2.208394\n",
      "  0.31002653 -1.4851222  -2.5132701   1.9179449   1.0733403  -2.0780675\n",
      "  1.8906293   6.125763   -1.4447007   2.4008942  -2.3162394  -0.5218772\n",
      " -0.64771026 -2.8467298  -0.56439835 -0.6517781  -1.1825156  -2.3549166\n",
      " -1.3687085  -1.7308933  -2.309236   -1.8280269   0.4556534   0.3254178\n",
      " -0.35976696 -2.9829307   1.5421295   1.7391022  -0.74924606  1.2280418\n",
      "  2.9335485  -3.8326027   0.9600574   0.42831966 -2.6927629  -5.330378  ]\n"
     ]
    }
   ],
   "source": [
    "#the vector representation of the word woman\n",
    "vector = model.wv['woman']\n",
    "print(f\"Vector representation of 'woman': {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c705332e-7d5a-4dc0-a08f-86874f4786f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result: [('queen', 0.4924481213092804)]\n"
     ]
    }
   ],
   "source": [
    "#word analogy\n",
    "analogy_result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Word analogy result: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b0f724-42bf-4f4e-8a72-c04438a54f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result: [('mother', 0.5855175256729126)]\n"
     ]
    }
   ],
   "source": [
    "#word analogy\n",
    "analogy_result = model.wv.most_similar(positive=['father', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Word analogy result: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76459078-e422-4536-8ae3-8aaec5827c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result: [('sex', 0.3916843831539154)]\n"
     ]
    }
   ],
   "source": [
    "#word analogy\n",
    "analogy_result = model.wv.most_similar(positive=['human', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Word analogy result: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1353424d-4d98-420c-b393-c8dc9178cab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result: [('baronet', 0.5580355525016785)]\n"
     ]
    }
   ],
   "source": [
    "#word analogy\n",
    "analogy_result = model.wv.most_similar(positive=['gentleman', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Word analogy result: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf03a81-2631-4baa-96db-fc7c754f923e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result: [('faithful', 0.3875488042831421)]\n"
     ]
    }
   ],
   "source": [
    "#word analogy\n",
    "analogy_result = model.wv.most_similar(positive=['loyal', 'woman'], negative=['man'], topn=1)\n",
    "print(f\"Word analogy result: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb3e553e-52e2-4de5-bbe5-8300b5f53717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Visualize embeddings of 'man' and 'woman'\n",
    "words_to_visualize = ['man', 'woman']\n",
    "vectors_to_visualize = np.array([model.wv[word] for word in words_to_visualize])\n",
    "\n",
    "# Check the number of samples\n",
    "n_samples, n_features = vectors_to_visualize.shape\n",
    "\n",
    "# Ensuring perplexity is less than the number of samples\n",
    "perplexity = min(3, n_samples - 1)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "vectors_2d = tsne.fit_transform(vectors_to_visualize)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.xlim(vectors_2d[:, 0].min() - 0.1, vectors_2d[:, 0].max() + 0.1)\n",
    "plt.ylim(vectors_2d[:, 1].min() - 0.1, vectors_2d[:, 1].max() + 0.1)\n",
    "\n",
    "for i, word in enumerate(words_to_visualize):\n",
    "    plt.scatter(vectors_2d[i, 0], vectors_2d[i, 1])\n",
    "    plt.text(vectors_2d[i, 0] + 0.02, vectors_2d[i, 1] + 0.02, word)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64a0ea-a2f3-40c5-b3c3-88f18a18ff7b",
   "metadata": {},
   "source": [
    "# Word2Vec for the year 1800-1849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73105c09-d8c0-494b-8dce-362037745fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1800_1849_tokenized.txt\n",
      "Processed 455320 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1800_1849_tokenized.txt\n",
      "Word2Vec Model training completed\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "#the path to the tokenized file \n",
    "file_path = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1800_1849_tokenized.txt'\n",
    "\n",
    "# Print statement for indicating the processing of the file\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "# Read the tokenized data from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.split() for line in file]\n",
    "    print(f\"Processed {len(sentences)} sentences from {file_path}\")\n",
    "\n",
    "    \n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model_1.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c1294bc-5a62-4be3-a2d6-11c8a5052b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the saved Word2Vec model\n",
    "model = Word2Vec.load('word2vec_model_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e8c2e88-a410-4332-8977-d972679def30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'woman': [('girl', 0.6130533218383789), ('female', 0.6100981831550598), ('wife', 0.5985001921653748), ('child', 0.5464219450950623), ('husband', 0.5307227969169617), ('seducer', 0.5158628225326538), ('daughter', 0.49284297227859497), ('unmarried', 0.4820486605167389), ('married', 0.4728690981864929), ('dog', 0.46741360425949097)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=10)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff3aae1d-3c8b-40e0-86d3-0e4af68f6f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'man': [('men', 0.499930202960968), ('creature', 0.4199649691581726), ('fool', 0.3968293070793152), ('englishman', 0.3779997229576111), ('wretch', 0.3754134774208069)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e34845-e08c-4793-b5a7-35bfc87cdd04",
   "metadata": {},
   "source": [
    "# Word2Vec for the year 1850-1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54902e06-cb5f-4aed-8015-fabf5abd5a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1850_1920_tokenized.txt\n",
      "Processed 942551 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1850_1920_tokenized.txt\n",
      "Word2Vec Model training completed\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "# the path to the tokenized file \n",
    "file_path = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1850_1920_tokenized.txt'\n",
    "\n",
    "# Print statement for indicating the processing of the file\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "# Read the tokenized data from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.split() for line in file]\n",
    "    print(f\"Processed {len(sentences)} sentences from {file_path}\")\n",
    "\n",
    "    \n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model_2.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b541db4f-80c6-4b1a-ada0-2d47f399321c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved Word2Vec model\n",
    "model = Word2Vec.load('word2vec_model_2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d03839a6-3c2c-43dd-99b2-da411ee290e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'woman': [('sex', 0.6105426549911499), ('female', 0.5254074931144714), ('adult', 0.5126000642776489), ('wife', 0.5085448026657104), ('girl', 0.49538668990135193)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=5)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b8e7168-e45a-4e1a-9136-391acbc8fcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to 'man': [('men', 0.5996216535568237), ('person', 0.4655570685863495), ('policeman', 0.43965616822242737), ('sparrowbill', 0.42352280020713806), ('fool', 0.41849204897880554)]\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc32a1-587b-4c43-bfb6-a6fc6a027b97",
   "metadata": {},
   "source": [
    "# Word2Vec for the year 1921-1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "292b5f0d-8551-46e7-9fea-a98ce2ec3ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1921_1970_tokenized.txt\n",
      "Processed 1339764 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1921_1970_tokenized.txt\n",
      "Word2Vec Model training completed\n",
      "Similar words to 'woman': [('men', 0.555997908115387), ('wife', 0.4957621097564697), ('sex', 0.47074177861213684), ('young', 0.4678460955619812), ('girl', 0.459478497505188)]\n",
      "Similar words to 'man': [('men', 0.6451320648193359), ('lad', 0.5397100448608398), ('someone', 0.5368929505348206), ('husband', 0.5136544108390808), ('wife', 0.4950489401817322)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "#the path to the tokenized file \n",
    "file_path = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1921_1970_tokenized.txt'\n",
    "\n",
    "# Print statement for indicating the processing of the file\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "# Read the tokenized data from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.split() for line in file]\n",
    "    print(f\"Processed {len(sentences)} sentences from {file_path}\")\n",
    "\n",
    "    \n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model_3.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")\n",
    "# Load the saved Word2Vec model\n",
    "model = model = Word2Vec.load('word2vec_model_3.bin')\n",
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=5)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")\n",
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfaa6b-5a51-4ffb-906f-63a3abd9cc84",
   "metadata": {},
   "source": [
    "# Word2Vec for the year  1971-1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d01861a-a217-4b40-b279-8f9a98e0fefd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1971_1990_tokenized.txt\n",
      "Processed 1025994 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1971_1990_tokenized.txt\n",
      "Word2Vec Model training completed\n",
      "Similar words to 'woman': [('men', 0.5502896308898926), ('mother', 0.4836650788784027), ('marries', 0.45573902130126953), ('returners', 0.45136409997940063), ('inspectorinspectorsergeantconstabletotal', 0.44561102986335754)]\n",
      "Similar words to 'man': [('men', 0.6083616018295288), ('chap', 0.5421302914619446), ('someone', 0.5174940824508667), ('wife', 0.4833219647407532), ('father', 0.45133188366889954)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "#the path to the tokenized file \n",
    "file_path = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1971_1990_tokenized.txt'\n",
    "\n",
    "# Print statement for indicating the processing of the file\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "# Read the tokenized data from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.split() for line in file]\n",
    "    print(f\"Processed {len(sentences)} sentences from {file_path}\")\n",
    "\n",
    "    \n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model_4.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")\n",
    "# Load the saved Word2Vec model\n",
    "model = model = Word2Vec.load('word2vec_model_4.bin')\n",
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=5)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")\n",
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49727c3-cd56-48ab-8555-6c6c76e96bc8",
   "metadata": {},
   "source": [
    "# Word2Vec for the year 1991-2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25069508-b51c-469c-b591-70b04c6e5c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1991_2006_tokenized.txt\n",
      "Processed 597305 sentences from /Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1991_2006_tokenized.txt\n",
      "Word2Vec Model training completed\n",
      "Similar words to 'woman': [('men', 0.6055730581283569), ('bisexual', 0.497183620929718), ('pregnant', 0.45050108432769775), ('childbirth', 0.4457819163799286), ('gay', 0.4387279748916626)]\n",
      "Similar words to 'man': [('men', 0.5722330808639526), ('someone', 0.500737190246582), ('son', 0.4917178452014923), ('daughter', 0.4793843626976013), ('husband', 0.47809159755706787)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "#the path to the tokenized file \n",
    "file_path = '/Users/shaistasyeda/Desktop/DataSet/tokenized_debates/new-tokenized-debates/1991_2006_tokenized.txt'\n",
    "\n",
    "# Print statement for indicating the processing of the file\n",
    "print(f\"Processing file: {file_path}\")\n",
    "\n",
    "# Read the tokenized data from the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.split() for line in file]\n",
    "    print(f\"Processed {len(sentences)} sentences from {file_path}\")\n",
    "\n",
    "    \n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=15, min_count=5, workers=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('word2vec_model_5.bin')\n",
    "\n",
    "print(\"Word2Vec Model training completed\")\n",
    "# Load the saved Word2Vec model\n",
    "model = model = Word2Vec.load('word2vec_model_5.bin')\n",
    "# Find words similar to the word woman\n",
    "similar_words = model.wv.most_similar('woman', topn=5)\n",
    "print(f\"Similar words to 'woman': {similar_words}\")\n",
    "# Find words similar to the word man\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "print(f\"Similar words to 'man': {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ca9e9-df9b-4c7c-aa4c-9ad2024048b9",
   "metadata": {},
   "source": [
    "# Word Analogy differences between all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df84b8a1-c201-47d1-9dee-51c3259b5fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_1849 = Word2Vec.load('word2vec_model_1.bin')\n",
    "model_1920 = Word2Vec.load('word2vec_model_2.bin')\n",
    "model_1970 = Word2Vec.load('word2vec_model_3.bin')\n",
    "model_1990 = Word2Vec.load('word2vec_model_4.bin')\n",
    "model_2006 = Word2Vec.load('word2vec_model_5.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6d17b-8905-4550-a326-786341fdf96d",
   "metadata": {},
   "source": [
    "# Association of woman to childbirth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73eb5c-3b40-4aa7-a151-92c35b92c7cb",
   "metadata": {},
   "source": [
    "## For the year 1800-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce57d2ab-d357-40fe-9bf5-5e887c12759e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result for the year 1800-1849: [('childish', 0.2966958284378052)]\n",
      "Word analogy result for the year 1850-1920: [('doctor', 0.3391333520412445)]\n",
      "Word analogy result for the year 1921-1970: [('pregnancy', 0.4149561822414398)]\n",
      "Word analogy result for the year 1971-1990: [('manasked', 0.34653785824775696)]\n",
      "Word analogy result for the year 1991-2006: [('walked', 0.36458632349967957)]\n"
     ]
    }
   ],
   "source": [
    "analogy_result = model_1849.wv.most_similar(positive=['childbirth', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1800-1849: {analogy_result}\")\n",
    "analogy_result = model_1920.wv.most_similar(positive=['childbirth', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1850-1920: {analogy_result}\")\n",
    "analogy_result = model_1970.wv.most_similar(positive=['childbirth', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1921-1970: {analogy_result}\")\n",
    "analogy_result = model_1990.wv.most_similar(positive=['childbirth', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1971-1990: {analogy_result}\")\n",
    "analogy_result = model_2006.wv.most_similar(positive=['childbirth', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1991-2006: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e37ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy result for the year 1800-1849: [('creature', 0.29993459582328796)]\n",
      "Word analogy result for the year 1850-1920: [('mortal', 0.3551318943500519)]\n",
      "Word analogy result for the year 1921-1970: [('chap', 0.3808192014694214)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'seducer' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m model_1970\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseducer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m], negative\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m], topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord analogy result for the year 1921-1970: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalogy_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m model_1990\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseducer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m], negative\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m], topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord analogy result for the year 1971-1990: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalogy_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m model_2006\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseducer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m], negative\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m], topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'seducer' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "analogy_result = model_1849.wv.most_similar(positive=['seducer', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1800-1849: {analogy_result}\")\n",
    "analogy_result = model_1920.wv.most_similar(positive=['seducer', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1850-1920: {analogy_result}\")\n",
    "analogy_result = model_1970.wv.most_similar(positive=['seducer', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1921-1970: {analogy_result}\")\n",
    "analogy_result = model_1990.wv.most_similar(positive=['seducer', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1971-1990: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67f00ffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'seducer' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m model_2006\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseducer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m], negative\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m], topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord analogy result for the year 1991-2006: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manalogy_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'seducer' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "analogy_result = model_2006.wv.most_similar(positive=['seducer', 'man'], negative=['woman'], topn=1)\n",
    "print(f\"Word analogy result for the year 1991-2006: {analogy_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ce986-d075-4cdc-88e5-58daa6284395",
   "metadata": {},
   "source": [
    "# Statements where the word \"SEDUCER\" is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1351bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c5562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shaistasyeda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe23d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_text_files(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270ca768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the corpus from a file\n",
    "def load_corpus(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5581b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find sentences\n",
    "def find_sentences_containing_word(sentences, word, filename):\n",
    "    return {(sentence, filename) for sentence in sentences if word in sentence.lower()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b2a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print full sentences with file info\n",
    "def print_full_sentences(sentences_with_files):\n",
    "    for sentence, filename in sentences_with_files:\n",
    "        print(f\"File: {filename}\\nSentence: {sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671982c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1839_merged.txt\n",
      "Sentence: He declared that the bastardy enactments had, in many cases, operated to give perfect impunity to the seducer; while it caused, but too often, the suicide of the female, or the murder of the offspring.\n",
      "\n",
      "File: 1835_merged.txt\n",
      "Sentence: not upon the priest; not upon the seducer;no, but upon the unfortunate woman, and her children!\n",
      "\n",
      "File: 1822_merged.txt\n",
      "Sentence: \"He knew the law under which these men were proceeded against was an old one; but whatever justice there might be in proceeding against Craven, as the seducer of artificers to leave the country, it was an extraordinary hardship that the men themselves should be pun-\n",
      "\n",
      "657\n",
      "ished for attempting to take their industry to a place where they saw the best choice of gaining a livelihood.\n",
      "\n",
      "File: 1857_merged.txt\n",
      "Sentence: and learned Gentleman meant to say was, that the adultress should be compelled to remain single during the life of her former husband.said, he thought that if they prevented the intermarriage of the guilty parties, so far from promoting morality, they would simply encourage seduction, by freeing the seducer from the obligation which society imposed upon him of compensating by marriage the woman whom he had wronged.said, as the Amendment of which he had given notice had been virtually negatived by the division just taken, he did not feel justified in pressing it upon the Committee.said, he had an Amendment to propose which would require him to make a statement of some length.\n",
      "\n",
      "File: 1986_merged.txt\n",
      "Sentence: Protectionism is the great seducer of older, traditional industries and, I believe, should be spurned.\n",
      "\n",
      "File: 1876_merged.txt\n",
      "Sentence: Let the shame of its fall rest on the head of the seducer; but to it let not the glory be denied of having produced a greater proportion of learned, eloquent, and honourable men than there were ever before congregated in a single Legislative Chamber.\n",
      "\n",
      "File: 1834_merged.txt\n",
      "Sentence: It is, Sir, a Bill of the most monstrous tyranny, and of the grossest injustice; and for this reason I shall vote against its third reading.said, that if the noble Lord would pursue his inquiries in order to bring conviction home to those who were equally guilty with the humble freeman, he should have his cordial support.was of opinion, that the vengeance of the House ought to fall on the seducers, and not on the seduced.\n",
      "\n",
      "File: 1861_merged.txt\n",
      "Sentence: It gave an opportunity to the seducer to inveigle a virtuous young woman into a snare, and enabled him, when his passions were satiated, to get rid of her.\n",
      "\n",
      "File: 1904_merged.txt\n",
      "Sentence: It is a source of great discomfort and alarm to find that policemen, who should protect the public and farmers' daughters walking along the roads, are found in the ranks of seducers.\n",
      "\n",
      "File: 1845_merged.txt\n",
      "Sentence: Mr. Mayer went to the house of the seducer and committed an assault upon him by striking him with a stick.\n",
      "\n",
      "File: 1834_merged.txt\n",
      "Sentence: By the  th,  th, and  st clauses, they had declared that in future the burthen of an illegitimate child should be entirely thrown on the mother, and that all responsibility should be removed from the putative father, or in other words that the woman was the seducer, and the man the seduced.\n",
      "\n",
      "File: 1965_merged.txt\n",
      "Sentence: This will require Commonwealth consultation with a view to reciprocal legislation in Commonwealth countries.Illegitimacy29.asked the Secretary of State for the Home Department whether he is aware that the seducer of a married woman living with her husband cannot be ordered to make any payment for a child born out of the affair; and whether he will seek to amend the Affiliation Act to ensure that such putative fathers no longer can escape from their responsibilities to their children.\n",
      "\n",
      "File: 1809_merged.txt\n",
      "Sentence: He thought, too, that it was a measure of unparalleled cruelty to some individuals, who would be thereby deprived of all hope, and abandoned to a life of despair, exclusion and penance, that the hardiest of their seducers would shrink from the bare contemplation of; besides that, there was in the nature of such an Order an unwarrantable interference with the privileges of that house.\n",
      "\n",
      "File: 1857_merged.txt\n",
      "Sentence: With regard to the pecuniary fine, it was quite clear that the wealthy seducer of his neighbour's wife, if he only paid the money, might marry or discard the woman as he chose, and then nothing more would be said about it; while the poor man would be sent to prison, not because he had committed a great offence, but because he had not the money wherewith to condone it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"/Users/shaistasyeda/Desktop/DataSet/merged-files\"  \n",
    "file_list = get_list_of_text_files(directory_path)\n",
    "\n",
    "all_sentences = set()\n",
    "\n",
    "for file in file_list:\n",
    "    corpus = load_corpus(file)\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    \n",
    "    context_sentences_for_seducer = find_sentences_containing_word(sentences, \"seducer\", os.path.basename(file))\n",
    "    all_sentences.update(context_sentences_for_seducer)\n",
    "\n",
    "print_full_sentences(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ec1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
