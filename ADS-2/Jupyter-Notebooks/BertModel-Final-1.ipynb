{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory path\n",
    "directory = \"/Users/shaistasyeda/Desktop/DataSet/TextFiles\"\n",
    "\n",
    "# Create a new file to store the merged contents\n",
    "for year in range(1803, 2007):\n",
    "    output_file_path = f\"{year}-merged.txt\"\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        # Loop through all files in the directory\n",
    "        for filename in os.listdir(directory):\n",
    "            # Check if the filename contains the year\n",
    "            if str(year) in filename:\n",
    "                # Open the file and read the contents\n",
    "                with open(os.path.join(directory, filename), \"r\") as file:\n",
    "                    contents = file.read()\n",
    "                    # Write the contents to the merged file\n",
    "                    output_file.write(contents)\n",
    "\n",
    "    print(f'Merged data for {year} and saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1618e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data files\n",
    "data_directory = '/Users/shaistasyeda/Desktop/DataSet/Merged-files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9866b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize and format data\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_data = file.readlines()\n",
    "\n",
    "    # Extract year from the file name using regular expression\n",
    "    year_match = re.search(r'(\\d{4})-merged\\.txt', file_path)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract the year from the file name: {file_path}\")\n",
    "\n",
    "    # Tokenize and format data for BERT\n",
    "    tokenized_data = []\n",
    "    for text in text_data:\n",
    "        tokenized_input = tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
    "        tokenized_data.append({\n",
    "            'text': text.strip(),  # Add the actual text to the DataFrame\n",
    "            'input_ids': tokenized_input['input_ids'].squeeze().tolist(),\n",
    "            'attention_mask': tokenized_input['attention_mask'].squeeze().tolist(),\n",
    "            'year': year\n",
    "        })\n",
    "\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cebd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files in the data directory\n",
    "all_data = []\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\"-merged.txt\"):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        tokenized_data = process_file(file_path)\n",
    "        all_data.extend(tokenized_data)\n",
    "        # Delete the original file\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenized data to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame \n",
    "df.to_parquet('/Users/shaistasyeda/Desktop/DataSet/tokenized_data_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d439dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f8b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Parquet DataFrame\n",
    "df = pd.read_parquet('/Users/shaistasyeda/Desktop/DataSet/tokenized_data_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6614f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                                      text  \\\n",
      "0        acquainted the House that their Address of Wed...   \n",
      "1        (Answered by Mr. A. J. Balfour.) I understand ...   \n",
      "2        (Answered by Mr. A. J. Balfour.) I am afraid I...   \n",
      "3        (Answered by Mr. Walter Long.) No opportunity ...   \n",
      "4        (Answered by Mr. Bonar Law.) The value of the ...   \n",
      "...                                                    ...   \n",
      "2282429  is the appropriate heading to which they shoul...   \n",
      "2282430  from interest allowable and interest disallowa...   \n",
      "2282431  premium bonds, for which there is a fixed limi...   \n",
      "2282432  respect of the financial year 1966–67, the num...   \n",
      "2282433  the Order, was to stop an unnecessary strain o...   \n",
      "\n",
      "                                                 input_ids  \\\n",
      "0        [101, 19056, 1996, 2160, 2008, 2037, 4769, 199...   \n",
      "1        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "2        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "3        [101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...   \n",
      "4        [101, 1006, 4660, 2011, 2720, 1012, 14753, 290...   \n",
      "...                                                    ...   \n",
      "2282429  [101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...   \n",
      "2282430  [101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...   \n",
      "2282431  [101, 12882, 9547, 1010, 2005, 2029, 2045, 200...   \n",
      "2282432  [101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...   \n",
      "2282433  [101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...   \n",
      "\n",
      "                                            attention_mask  year  \n",
      "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "...                                                    ...   ...  \n",
      "2282429  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282430  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282431  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282432  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282433  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "\n",
      "[2282434 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9718e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the labeling\n",
    "def label_year(year):\n",
    "    if 1850 <= year <= 1920:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9b846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      text  \\\n",
      "0        acquainted the House that their Address of Wed...   \n",
      "1        (Answered by Mr. A. J. Balfour.) I understand ...   \n",
      "2        (Answered by Mr. A. J. Balfour.) I am afraid I...   \n",
      "3        (Answered by Mr. Walter Long.) No opportunity ...   \n",
      "4        (Answered by Mr. Bonar Law.) The value of the ...   \n",
      "...                                                    ...   \n",
      "2282429  is the appropriate heading to which they shoul...   \n",
      "2282430  from interest allowable and interest disallowa...   \n",
      "2282431  premium bonds, for which there is a fixed limi...   \n",
      "2282432  respect of the financial year 1966–67, the num...   \n",
      "2282433  the Order, was to stop an unnecessary strain o...   \n",
      "\n",
      "                                                 input_ids  \\\n",
      "0        [101, 19056, 1996, 2160, 2008, 2037, 4769, 199...   \n",
      "1        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "2        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "3        [101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...   \n",
      "4        [101, 1006, 4660, 2011, 2720, 1012, 14753, 290...   \n",
      "...                                                    ...   \n",
      "2282429  [101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...   \n",
      "2282430  [101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...   \n",
      "2282431  [101, 12882, 9547, 1010, 2005, 2029, 2045, 200...   \n",
      "2282432  [101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...   \n",
      "2282433  [101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...   \n",
      "\n",
      "                                            attention_mask  year  label  \n",
      "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "...                                                    ...   ...    ...  \n",
      "2282429  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282430  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282431  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282432  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282433  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "\n",
      "[2282434 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['year'].apply(label_year)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c961be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>942621.0</td>\n",
       "      <td>1883.132608</td>\n",
       "      <td>20.579734</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339813.0</td>\n",
       "      <td>1952.192676</td>\n",
       "      <td>13.280689</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year                                                          \\\n",
       "           count         mean        std     min     25%     50%     75%   \n",
       "label                                                                      \n",
       "0       942621.0  1883.132608  20.579734  1850.0  1866.0  1880.0  1901.0   \n",
       "1      1339813.0  1952.192676  13.280689  1921.0  1944.0  1955.0  1963.0   \n",
       "\n",
       "               \n",
       "          max  \n",
       "label          \n",
       "0      1920.0  \n",
       "1      1970.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae75b13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7981e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20,000 rows from each class\n",
    "df_sampled_0 = df[df['label'] == 0].sample(n=10000, random_state=42)\n",
    "df_sampled_1 = df[df['label'] == 1].sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c7492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two sampled subsets\n",
    "df_sampled = pd.concat([df_sampled_0, df_sampled_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3867af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1882.6507</td>\n",
       "      <td>20.526608</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1952.1757</td>\n",
       "      <td>13.178490</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          year                                                              \n",
       "         count       mean        std     min     25%     50%     75%     max\n",
       "label                                                                       \n",
       "0      10000.0  1882.6507  20.526608  1850.0  1865.0  1879.0  1900.0  1920.0\n",
       "1      10000.0  1952.1757  13.178490  1921.0  1944.0  1955.0  1963.0  1970.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52df8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the combined dataset\n",
    "df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ffa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.to_csv('/Users/shaistasyeda/Desktop/DataSet/bert-dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d449a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b40778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bf08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_df, val_df = train_test_split(df_sampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c7c6a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaistasyeda/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df39d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids.iloc[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask.iloc[idx], dtype=torch.long),\n",
    "            'label': torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "821649f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    labels = [item['label'] for item in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f44bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataLoaders\n",
    "train_dataset = CustomDataset(train_df['input_ids'], train_df['attention_mask'], train_df['label'])\n",
    "val_dataset = CustomDataset(val_df['input_ids'], val_df['attention_mask'], val_df['label'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73dfbe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84696f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|███████████████████| 2000/2000 [5:06:24<00:00,  9.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 0.4342, Accuracy: 0.8015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|███████████████████| 2000/2000 [4:36:05<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Validation Loss: 0.3468, Accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|███████████████████| 2000/2000 [4:31:37<00:00,  8.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Validation Loss: 0.4823, Accuracy: 0.8105\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'],\n",
    "            'attention_mask': batch['attention_mask'],\n",
    "            'labels': batch['labels']  \n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "       # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_inputs = {\n",
    "                'input_ids': val_batch['input_ids'],\n",
    "                'attention_mask': val_batch['attention_mask'],\n",
    "                'labels': val_batch['labels']\n",
    "            }\n",
    "            val_outputs = model(**val_inputs)\n",
    "            val_loss += val_outputs.loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            logits = val_outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(predictions == val_batch['labels']).item()\n",
    "            total_samples += len(predictions)  \n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "901e825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/Users/shaistasyeda/Desktop/DataSet/bert_model_weights_20k.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c4c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe5b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
