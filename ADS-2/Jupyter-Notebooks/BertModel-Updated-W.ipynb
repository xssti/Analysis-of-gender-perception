{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory path\n",
    "directory = \"/Users/shaistasyeda/Desktop/DataSet/TextFiles\"\n",
    "\n",
    "# Create a new file to store the merged contents\n",
    "for year in range(1803, 2007):\n",
    "    output_file_path = f\"{year}-merged.txt\"\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        # Loop through all files in the directory\n",
    "        for filename in os.listdir(directory):\n",
    "            # Check if the filename contains the year\n",
    "            if str(year) in filename:\n",
    "                # Open the file and read the contents\n",
    "                with open(os.path.join(directory, filename), \"r\") as file:\n",
    "                    contents = file.read()\n",
    "                    # Write the contents to the merged file\n",
    "                    output_file.write(contents)\n",
    "\n",
    "    print(f'Merged data for {year} and saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1618e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data files\n",
    "data_directory = '/Users/shaistasyeda/Desktop/DataSet/Merged-files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9866b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize and format data\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text_data = file.readlines()\n",
    "\n",
    "    # Extract year from the file name using regular expression\n",
    "    year_match = re.search(r'(\\d{4})-merged\\.txt', file_path)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract the year from the file name: {file_path}\")\n",
    "\n",
    "    # Tokenize and format data for BERT\n",
    "    tokenized_data = []\n",
    "    for text in text_data:\n",
    "        tokenized_input = tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
    "        tokenized_data.append({\n",
    "            'text': text.strip(),  # Add the actual text to the DataFrame\n",
    "            'input_ids': tokenized_input['input_ids'].squeeze().tolist(),\n",
    "            'attention_mask': tokenized_input['attention_mask'].squeeze().tolist(),\n",
    "            'year': year\n",
    "        })\n",
    "\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cebd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all files in the data directory\n",
    "all_data = []\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\"-merged.txt\"):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        tokenized_data = process_file(file_path)\n",
    "        all_data.extend(tokenized_data)\n",
    "        # Delete the original file\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tokenized data to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame \n",
    "df.to_parquet('/Users/shaistasyeda/Desktop/DataSet/tokenized_data_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d439dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2f8b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Parquet DataFrame\n",
    "df = pd.read_parquet('/Users/shaistasyeda/Desktop/DataSet/tokenized_data_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6614f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                                      text  \\\n",
      "0        acquainted the House that their Address of Wed...   \n",
      "1        (Answered by Mr. A. J. Balfour.) I understand ...   \n",
      "2        (Answered by Mr. A. J. Balfour.) I am afraid I...   \n",
      "3        (Answered by Mr. Walter Long.) No opportunity ...   \n",
      "4        (Answered by Mr. Bonar Law.) The value of the ...   \n",
      "...                                                    ...   \n",
      "2282429  is the appropriate heading to which they shoul...   \n",
      "2282430  from interest allowable and interest disallowa...   \n",
      "2282431  premium bonds, for which there is a fixed limi...   \n",
      "2282432  respect of the financial year 1966–67, the num...   \n",
      "2282433  the Order, was to stop an unnecessary strain o...   \n",
      "\n",
      "                                                 input_ids  \\\n",
      "0        [101, 19056, 1996, 2160, 2008, 2037, 4769, 199...   \n",
      "1        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "2        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "3        [101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...   \n",
      "4        [101, 1006, 4660, 2011, 2720, 1012, 14753, 290...   \n",
      "...                                                    ...   \n",
      "2282429  [101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...   \n",
      "2282430  [101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...   \n",
      "2282431  [101, 12882, 9547, 1010, 2005, 2029, 2045, 200...   \n",
      "2282432  [101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...   \n",
      "2282433  [101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...   \n",
      "\n",
      "                                            attention_mask  year  \n",
      "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905  \n",
      "...                                                    ...   ...  \n",
      "2282429  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282430  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282431  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282432  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "2282433  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969  \n",
      "\n",
      "[2282434 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9718e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the labeling\n",
    "def label_year(year):\n",
    "    if 1850 <= year <= 1920:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef9b846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      text  \\\n",
      "0        acquainted the House that their Address of Wed...   \n",
      "1        (Answered by Mr. A. J. Balfour.) I understand ...   \n",
      "2        (Answered by Mr. A. J. Balfour.) I am afraid I...   \n",
      "3        (Answered by Mr. Walter Long.) No opportunity ...   \n",
      "4        (Answered by Mr. Bonar Law.) The value of the ...   \n",
      "...                                                    ...   \n",
      "2282429  is the appropriate heading to which they shoul...   \n",
      "2282430  from interest allowable and interest disallowa...   \n",
      "2282431  premium bonds, for which there is a fixed limi...   \n",
      "2282432  respect of the financial year 1966–67, the num...   \n",
      "2282433  the Order, was to stop an unnecessary strain o...   \n",
      "\n",
      "                                                 input_ids  \\\n",
      "0        [101, 19056, 1996, 2160, 2008, 2037, 4769, 199...   \n",
      "1        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "2        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
      "3        [101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...   \n",
      "4        [101, 1006, 4660, 2011, 2720, 1012, 14753, 290...   \n",
      "...                                                    ...   \n",
      "2282429  [101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...   \n",
      "2282430  [101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...   \n",
      "2282431  [101, 12882, 9547, 1010, 2005, 2029, 2045, 200...   \n",
      "2282432  [101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...   \n",
      "2282433  [101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...   \n",
      "\n",
      "                                            attention_mask  year  label  \n",
      "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
      "...                                                    ...   ...    ...  \n",
      "2282429  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282430  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282431  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282432  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "2282433  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
      "\n",
      "[2282434 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['year'].apply(label_year)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c961be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>942621.0</td>\n",
       "      <td>1883.132608</td>\n",
       "      <td>20.579734</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339813.0</td>\n",
       "      <td>1952.192676</td>\n",
       "      <td>13.280689</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year                                                          \\\n",
       "           count         mean        std     min     25%     50%     75%   \n",
       "label                                                                      \n",
       "0       942621.0  1883.132608  20.579734  1850.0  1866.0  1880.0  1901.0   \n",
       "1      1339813.0  1952.192676  13.280689  1921.0  1944.0  1955.0  1963.0   \n",
       "\n",
       "               \n",
       "          max  \n",
       "label          \n",
       "0      1920.0  \n",
       "1      1970.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae75b13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db04b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a list of keywords related to women\n",
    "keywords = ['woman', 'women', 'she', 'her', 'female', 'girl', 'lady', 'mother', 'daughter', 'aunt', 'niece']\n",
    "\n",
    "# Create a boolean mask for sentences that contain any of the keywords\n",
    "mask = df['text'].apply(lambda x: any(keyword in x.lower() for keyword in keywords))\n",
    "\n",
    "# Create a new DataFrame with only sentences that contain the keywords\n",
    "df_women_related = pd.DataFrame(df[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d204a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acquainted the House that their Address of Wed...</td>\n",
       "      <td>[101, 19056, 1996, 2160, 2008, 2037, 4769, 199...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Answered by Mr. A. J. Balfour.) I am afraid I...</td>\n",
       "      <td>[101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Answered by Mr. Walter Long.) No opportunity ...</td>\n",
       "      <td>[101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cattle ,  , Oats. ,  , : To ask the Secretary ...</td>\n",
       "      <td>[101, 7125, 1010, 1010, 1051, 11149, 1012, 101...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Answered by Mr. Secretary Akers-Douglas.) Thi...</td>\n",
       "      <td>[101, 1006, 4660, 2011, 2720, 1012, 3187, 1771...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282429</th>\n",
       "      <td>is the appropriate heading to which they shoul...</td>\n",
       "      <td>[101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282430</th>\n",
       "      <td>from interest allowable and interest disallowa...</td>\n",
       "      <td>[101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282431</th>\n",
       "      <td>premium bonds, for which there is a fixed limi...</td>\n",
       "      <td>[101, 12882, 9547, 1010, 2005, 2029, 2045, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282432</th>\n",
       "      <td>respect of the financial year 1966–67, the num...</td>\n",
       "      <td>[101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282433</th>\n",
       "      <td>the Order, was to stop an unnecessary strain o...</td>\n",
       "      <td>[101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163837 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0        acquainted the House that their Address of Wed...   \n",
       "2        (Answered by Mr. A. J. Balfour.) I am afraid I...   \n",
       "3        (Answered by Mr. Walter Long.) No opportunity ...   \n",
       "21       Cattle ,  , Oats. ,  , : To ask the Secretary ...   \n",
       "22       (Answered by Mr. Secretary Akers-Douglas.) Thi...   \n",
       "...                                                    ...   \n",
       "2282429  is the appropriate heading to which they shoul...   \n",
       "2282430  from interest allowable and interest disallowa...   \n",
       "2282431  premium bonds, for which there is a fixed limi...   \n",
       "2282432  respect of the financial year 1966–67, the num...   \n",
       "2282433  the Order, was to stop an unnecessary strain o...   \n",
       "\n",
       "                                                 input_ids  \\\n",
       "0        [101, 19056, 1996, 2160, 2008, 2037, 4769, 199...   \n",
       "2        [101, 1006, 4660, 2011, 2720, 1012, 1037, 1012...   \n",
       "3        [101, 1006, 4660, 2011, 2720, 1012, 4787, 2146...   \n",
       "21       [101, 7125, 1010, 1010, 1051, 11149, 1012, 101...   \n",
       "22       [101, 1006, 4660, 2011, 2720, 1012, 3187, 1771...   \n",
       "...                                                    ...   \n",
       "2282429  [101, 2003, 1996, 6413, 5825, 2000, 2029, 2027...   \n",
       "2282430  [101, 2013, 3037, 3499, 3085, 1998, 3037, 4487...   \n",
       "2282431  [101, 12882, 9547, 1010, 2005, 2029, 2045, 200...   \n",
       "2282432  [101, 4847, 1997, 1996, 3361, 2095, 3547, 1516...   \n",
       "2282433  [101, 1996, 2344, 1010, 2001, 2000, 2644, 2019...   \n",
       "\n",
       "                                            attention_mask  year  label  \n",
       "0        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
       "21       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
       "22       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1905      0  \n",
       "...                                                    ...   ...    ...  \n",
       "2282429  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
       "2282430  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
       "2282431  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
       "2282432  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
       "2282433  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  1969      1  \n",
       "\n",
       "[1163837 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_women_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7f2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_women_related.to_csv('/Users/shaistasyeda/Desktop/DataSet/bert-dataframe-related-woman.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ffc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405397.0</td>\n",
       "      <td>1884.574901</td>\n",
       "      <td>20.989863</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1867.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>758440.0</td>\n",
       "      <td>1952.488851</td>\n",
       "      <td>13.120405</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year                                                          \\\n",
       "          count         mean        std     min     25%     50%     75%   \n",
       "label                                                                     \n",
       "0      405397.0  1884.574901  20.989863  1850.0  1867.0  1883.0  1902.0   \n",
       "1      758440.0  1952.488851  13.120405  1921.0  1945.0  1955.0  1963.0   \n",
       "\n",
       "               \n",
       "          max  \n",
       "label          \n",
       "0      1920.0  \n",
       "1      1970.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_women_related.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "312c7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_women_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7981e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20,000 rows from each class\n",
    "df_sampled_0 = df[df['label'] == 0].sample(n=20000, random_state=42)\n",
    "df_sampled_1 = df[df['label'] == 1].sample(n=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1c7492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two sampled subsets\n",
    "df_sampled = pd.concat([df_sampled_0, df_sampled_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3867af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>1884.5336</td>\n",
       "      <td>21.076335</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1867.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>1952.4793</td>\n",
       "      <td>13.169033</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          year                                                              \n",
       "         count       mean        std     min     25%     50%     75%     max\n",
       "label                                                                       \n",
       "0      20000.0  1884.5336  21.076335  1850.0  1867.0  1883.0  1902.0  1920.0\n",
       "1      20000.0  1952.4793  13.169033  1921.0  1945.0  1955.0  1963.0  1970.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a52df8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the combined dataset\n",
    "df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25ffa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.to_csv('/Users/shaistasyeda/Desktop/DataSet/bert-dataframe-w.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b55bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('/Users/shaistasyeda/Desktop/DataSet/bert-dataframe-w.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7f260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab6c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and labels\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79bd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bert-small tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-4_H-512_A-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13f4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5d44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f431dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the train and validation sets\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeaafd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels into torch tensors\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fd64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad65bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "val_dataset = TextDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98bd0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c49a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load bert-small model\n",
    "model = BertForSequenceClassification.from_pretrained('google/bert_uncased_L-4_H-512_A-8', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66828215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaistasyeda/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c984c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Training Loss: 0.27244958000630143, Training Accuracy: 0.88253125\n",
      "Validation Loss: 0.21988102419674396, Validation Accuracy: 0.90625\n",
      "Epoch 2:\n",
      "Training Loss: 0.15135690008476377, Training Accuracy: 0.938625\n",
      "Validation Loss: 0.19077790389582513, Validation Accuracy: 0.921875\n",
      "Epoch 3:\n",
      "Training Loss: 0.08454910147190094, Training Accuracy: 0.968\n",
      "Validation Loss: 0.21479382083564996, Validation Accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "# Training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (outputs.logits.argmax(dim=-1) == batch['labels']).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0, 0\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_correct += (outputs.logits.argmax(dim=-1) == batch['labels']).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}:')\n",
    "    print(f'Training Loss: {avg_train_loss}, Training Accuracy: {train_accuracy}')\n",
    "    print(f'Validation Loss: {avg_val_loss}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c63329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W/tokenizer_config.json',\n",
       " '/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W/special_tokens_map.json',\n",
       " '/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W/vocab.txt',\n",
       " '/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('/Users/shaistasyeda/Desktop/DataSet/bert-model-W')\n",
    "tokenizer.save_pretrained('/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e68ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('/Users/shaistasyeda/Desktop/DataSet/bert-model-W')\n",
    "tokenizer = BertTokenizer.from_pretrained('/Users/shaistasyeda/Desktop/DataSet/bert-tokenizer-W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbebf1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "723dd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_statement(statement):\n",
    "    # Tokenize the statement\n",
    "    inputs = tokenizer(statement, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Get the predicted class (0 or 1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e86c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statement is classified as class 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "statement = \"women are seducers\"\n",
    "prediction = classify_statement(statement)\n",
    "print(f\"The statement is classified as class {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
