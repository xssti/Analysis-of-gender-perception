# -*- coding: utf-8 -*-
"""dataExtractiontoCSV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F9NdYxW4NZVw4_h12hwbucyRDhOUkH95

Shaista!
"""

# imports
from bs4 import BeautifulSoup as bs
import requests
import csv

def get_data(link):
 return requests.get(link)
 
def get_soup(data):
   soup = bs(data.content)
   return soup
 
def get_parser(data):
   text = data.text
   htmlParse = bs(text, "html.parser")
   return htmlParse

def write_to_csv(data, file_name):
  if(len(data) == 0):
    print("empty data")
    return
  titles = list(data[0].keys())
  with open(file_name, 'w') as outfile:
    writer = csv.writer(outfile)
    writer.writerow(titles)
    for item in data:
        values = list(item.values())
        writer.writerow(values)

def construct_data_list(links):
  hansard_info_list = []
  for link in links:
    hansard_info = {}
    data = get_data(link)
    soup = get_soup(data)
    hansard_info['date'] = soup.find(class_="sitting-day").get_text(" ", strip = True)
    parser = get_parser(data)
    hansard_info['title'] = parser.select('h1.title')[0].text.strip()
    hansard_info['conversation'] = [p.get_text(strip=True, separator='\n') for p in soup.find_all("p")]
    hansard_info['conversation'] = str(hansard_info['conversation'][:-1])
    hansard_info_list.append(hansard_info)
  return hansard_info_list

links  = ['https://api.parliament.uk/historic-hansard/commons/1999/jan/11/benefit-integrity-project', 'https://api.parliament.uk/historic-hansard/commons/1943/may/11/war-time-missions-united-states', 'https://api.parliament.uk/historic-hansard/commons/1999/jan/11/delegated-legislation']
data = construct_data_list(links)

write_to_csv(data, 'sample.csv')

